data:
    modality: "pose"
    train_pipeline:
        dataset:
          _target_: openhands.datasets.isolated.fingerspelling.FingerSpellingDataset
          root_dir: "/datadrive/fingerspelling_dataset"
          splits: "train"
          modality: "pose"
          seq_len: 10
          num_seq: 6

        transforms:
            - PoseSelect:
                preset: mediapipe_holistic_minimal_27
            - PoseUniformSubsampling:
                num_frames: 60
            - CenterAndScaleNormalize:
                reference_points_preset: shoulder_mediapipe_holistic_minimal_27
            - ShearTransform:
                shear_std: 0.1
            - RotatationTransform:
                rotation_std: 0.1

        dataloader:
            _target_: torch.utils.data.DataLoader
            batch_size: 16
            shuffle: true
            num_workers: 6
            pin_memory: true
            # drop_last: true

    valid_pipeline:
        dataset:
              _target_: openhands.datasets.isolated.fingerspelling.FingerSpellingDataset
              root_dir: "/datadrive/fingerspelling_dataset"
              splits: "test"
              modality: "pose"
              seq_len: 10
              num_seq: 6

        transforms:
            - PoseSelect:
                preset: mediapipe_holistic_minimal_27
            - PoseUniformSubsampling:
                num_frames: 60
            - CenterAndScaleNormalize:
                reference_points_preset: shoulder_mediapipe_holistic_minimal_27

        dataloader:
            _target_: torch.utils.data.DataLoader
            batch_size: 32
            shuffle: false
            num_workers: 8
            pin_memory: true
            drop_last: false
    
model:
    pretrained:
      type: dpc
      load_from:
        cfg_file: /home/iitm/OpenHands/examples/ssl/pretrain_dpc_stgcn.yaml
        ckpt: /datadrive/PretrainedCheckpoints/epoch=499-step=308499.ckpt

optim:
    loss: 'CrossEntropyLoss'
    optimizer:
        name: Adam
        params:
            lr: 1e-3

    scheduler:
        name: CosineAnnealingLR
        params:
            last_epoch: -1
            T_max: 20

trainer:
    gpus: 1
    max_epochs: 500
    # resume_from_checkpoint: /home/gokulnc/openhands/openhands_experiments/INCLUDE/BERT-Fine-tuned-full/epoch=1493-step=82169.ckpt

exp_manager:
    create_tensorboard_logger: true
    create_wandb_logger: true
    wandb_logger_kwargs:
        name: "finetune_raw_dpc_60Uniformsubsampling_ase"
        project: "fingerspelling"

    create_checkpoint_callback: true
    checkpoint_callback_params:
        monitor: "val_acc"
        mode: "max"
        save_top_k: 3
        dirpath: "experiments/fingerspelling/pretraining/finetune_raw_dpc_60Uniformsubsampling_ase/"

    early_stopping_callback: true
    early_stopping_params:
        monitor: "val_acc"
        patience: 100
        verbose: true
        mode: "max"